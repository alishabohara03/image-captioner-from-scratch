ğŸ“¸ Image Caption Generator â€” End-to-End ML + FastAPI + React Application

An end-to-end Image Caption Generation System built entirely from scratch without using any pretrained models.
This project combines Machine Learning, Deep Learning, FastAPI, PostgreSQL, and a modern React frontend to generate natural-language captions for images.

The primary goal of this project is to understand and design a complete ML workflow â€” from dataset preparation to model training to a full-stack deployment-ready system.

ğŸš€ Tech Stack Overview
ğŸ”§ Frontend

React (Vite)

Tailwind CSS

Axios

JWT handling & protected routes

âš™ï¸ Backend

FastAPI

PostgreSQL + SQLAlchemy ORM

JWT Authentication

Uvicorn server

Pydantic validation

ğŸ§  Machine Learning

Custom CNN (trained from scratch)

LSTM-based caption generator

Custom tokenizer + vocabulary

Trained locally on Flickr30k dataset

ğŸ“‚ Project Structure
.
â”œâ”€â”€ frontend/                    # React Application
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ models/                 # ML model files (ignored in Git)
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

ğŸ§  Machine Learning Workflow

This project uses two deep learning models, trained completely from scratch:

1ï¸âƒ£ Custom CNN Feature Extractor

Built and trained without pretrained weights.

Extracts visual features from images.

Generates dense feature vectors used by the caption generator.

2ï¸âƒ£ LSTM Caption Generator

Trained using cleaned captions from Flickr30k.

Embedding â†’ LSTM â†’ Dense softmax output.

Generates captions word-by-word.

Training Pipeline Summary

Clean & normalize captions

Build vocabulary

Create token sequences

Train CNN

Train LSTM Caption model

Save:

feature_extractor.keras

model.keras

tokenizer.pkl

These files are placed in:

backend/models/


(ignored from Git)

âš™ï¸ Backend Setup (FastAPI)
1ï¸âƒ£ Install Dependencies
pip install -r backend/requirements.txt

2ï¸âƒ£ Configure .env

Create backend/.env:

DATABASE_URL=postgresql://user:password@localhost:5432/caption_db
JWT_SECRET=your_secret_key

3ï¸âƒ£ Add Model Files

Place the following inside backend/models/:

feature_extractor.keras

model.keras

tokenizer.pkl

4ï¸âƒ£ Run the Backend
uvicorn app.main:app --reload


Backend will be available at:

http://localhost:8000

ğŸ“¡ API Endpoints
ğŸ” Authentication
Method	Endpoint	Description
POST	/auth/signup	Register a new user
POST	/auth/login	Login and receive JWT token
ğŸ–¼ï¸ Caption Generation
Method	Endpoint	Description
POST	/caption/upload	Upload an image and generate caption

Input:
multipart/form-data â†’ image

ğŸ“œ History Management
Method	Endpoint	Auth	Description
GET	/history/recent	âœ”	Fetch last 3 generated captions
GET	/history/all?page=1&limit=10	âœ”	Paginated history for the user
ğŸ’» Frontend Setup (React + Vite)
1ï¸âƒ£ Install Dependencies
cd frontend
npm install

2ï¸âƒ£ Run the Frontend
npm run dev


Frontend will run on:

http://localhost:5173

ğŸŒŸ Features
ML

Custom CNN trained from scratch

LSTM caption generator

Vocabulary + tokenizer built manually

Backend

Secure auth using JWT

Image processing + caption inference API

User-specific caption history

Pagination supported

Frontend

Upload image â†’ view caption instantly

Clean and responsive UI

Login/Register system

Dashboard with recent & full history